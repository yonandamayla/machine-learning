{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "518f7dc3-55ff-4c2e-8ffb-5898f7bee935",
   "metadata": {},
   "source": [
    "# Multi Layer Perceptron\n",
    "Multi Layer Perceptron (MLP) adalah sebuah jaringan saraf yang terdiri dari satu layer input, satu atau lebih hidden layer, dan satu output layer. MLP yang memiliki banyak hidden layer disebut juga Deep Neural Network (DNN).\n",
    "\n",
    "# feedforward neural network (FNN).\n",
    "Backpropagation adalah gradient descent dengan teknik yang efisien untuk menghitung gradien secara otomatis hanya dalam dua lintasan (satu maju dan satu mundur). Algoritma ini mampu menghitung gradien kesalahan jaringan dengan memperhatikan setiap parameter model. Ia dapat mengetahui bagaimana setiap bobot koneksi dan bias harus disesuaikan untuk mengurangi kesalahan. Setelah memperoleh gradien yang diinginkan, proses dilanjutkan dengan gradient descent biasa dan seluruh proses diulang sampai jaringan menyatu dengan solusi.\n",
    "\n",
    "# Propagasi Balik\n",
    "Algoritma propagasi balik memungkinkan MLP untuk belajar membuat prediksi menjadi semakin baik dengan suatu teknik yang disebut chain rule. Algoritma ini bekerja dengan cara berikut :\n",
    "1. Algoritma ini menangani satu kelompok kecil dalam satu waktu dan melewati keseluruhan set training beberapa kali. Tiap satu lintasan set training kita menyebutnya dengan istilah satu epoch.\n",
    "2. Selanjutnya algoritma menghitung output semua neuron dalam satu layer. Hasilnya diteruskan ke layer berikutnya, dihitung lagi outputnya, dan diteruskan lagi ke layer berikutnya. Demikian seterusnya sampai kita mendapatkan output dari layer terakhir, layer output. Proses ini disebut forward pass, mirip seperti teknik membuat prediksi. Bedanya adalah seluruh hasil pada tahapan menengah disimpan untuk proses backward pass (umpan mundur).\n",
    "3. Keluaran hasil prediksi kemudian diukur tingkat erornya menggunakan loss function dengan cara membandingkan output yang diinginkan dan output dari jaringan. \n",
    "4. Algoritma kemudian melewati setiap lapisan secara terbalik atau mundur hingga mencapai layer input untuk mengukur kontribusi kesalahan dari setiap kesalahan. Proses ini dilakukan secara analitis dengan menerapkan aturan rantai atau chain rule yang membuat langkah ini cepat dan tepat.\n",
    "5. Terakhir, algoritma melakukan langkah penurunan gradien untuk mengubah dan  menyesuaikan bobot koneksi di jaringan. Proses ini bertujuan untuk meminimalisir eror.\n",
    "\n",
    "Sebuah contoh sederhana dari propagasi balik adalah pada permainan Angry Birds. Kita dapat memenangkan permainan dengan memilih lintasan terbaik untuk mengenai target. Pada awal permainan MLP akan memilih lintasan secara acak. Pada pemilihan lintasan pertama, MLP sangat mungkin menghasilkan eror berupa tak kena target. Eror kemudian diukur dengan loss function di mana eror merupakan jarak antara lintasan yang tidak mengenai target dan target yang dituju. Eror kemudian dikirim dengan propagasi balik dan setiap bobot pada MLP disesuaikan dengan optimizer.\n",
    "\n",
    "Pada kasus ini bobot yang perlu dipelajari MLP adalah lintasan terbaik yang harus dilalui untuk memenangkan permainan. Kemudian MLP akan terus belajar dengan propagasi balik hingga akhirnya menemukan bobot/lintasan yang berhasil mengenai target.\n",
    "Cara Kerja : \n",
    "1. https://towardsdatascience.com/understanding-backpropagation-algorithm-7bb3aa2f95fd\n",
    "2. https://brilliant.org/wiki/backpropagation/\n",
    "\n",
    "# Klasifikasi dengan MLP\n",
    "Setelah kita memahami perceptron, multi layer perceptron, dan propagasi balik, kita dapat melihat bagaimana MLP bekerja. MLP adalah model machine learning kategori supervised sehingga MLP dapat dipakai dalam kasus klasifikasi dan regresi. Tak ada aturan baku tentang pemilihan jumlah hidden layer dan banyak perceptronnya. Jumlah hidden layer dapat disesuaikan dengan kerumitan masalah yang akan diselesaikan. Ketika telah melalui beberapa iterasi kita dapat melihat beberapa garis menjadi lebih tebal dari lainnya. Garis yang lebih tebal menunjukkan bahwa bobotnya lebih tinggi. Dari seluruh bobot yang dipelajari, prediksi MLP pada iterasi terakhir akan menjadi lebih tepat."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
