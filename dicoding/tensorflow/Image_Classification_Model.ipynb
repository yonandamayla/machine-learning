{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c585210-362d-4b8d-bc32-af919dd93322",
   "metadata": {},
   "source": [
    "Tahap awal sebelum kita membangun sebuah model machine learning adalah mendefinisikan problem statement yang ingin kita selesaikan. Pada tahap ini kita menentukan apa masalah yang ingin diselesaikan dan bagaimana implementasi dari model jaringan saraf tiruan dapat menyelesaikan masalah tersebut. Setelah kita memahami masalah, kita dapat mengembangkan model jaringan saraf tiruan sebagai sebuah solusi.\n",
    "\n",
    "Pada latihan kali ini kita akan membuat sebuah model untuk mengklasifikasi gambar sebuah kamar dan memprediksi apakah kamar tersebut rapi atau berantakan. \n",
    "\n",
    "Tentunya machine learning selalu membutuhkan data. Pada tahap awal kita perlu memahami dataset yang kita miliki terlebih dahulu. Beberapa hal yang perlu diketahui adalah format dari data, jumlah sampel, dan berapa jumlah label. Selain itu, kita juga perlu memastikan apakah dataset tersebut merupakan data kontinu (masalah regresi) atau data diskrit (masalah klasifikasi).\n",
    "\n",
    "Dataset yang kita gunakan memiliki 192 sampel data latih yang terdiri dari 96 sampel gambar ruangan rapi dan 96 sampel gambar ruangan berantabkan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0cb9e6",
   "metadata": {},
   "source": [
    "Hal pertama yang perlu dilakukan adalah memastikan bahwa versi TensorFlow yang Anda gunakan adalah versi 2 ke atas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdc818d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\YONANDA MAYLA\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2.15.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38294876",
   "metadata": {},
   "source": [
    "Tahap selanjutnya adalah mempersiapkan dataset yang akan digunakan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1984d723",
   "metadata": {},
   "source": [
    "Kode di bawah ini berfungsi untuk mengekstrak data yang sebelumnya kita unduh. Lalu kita mendefinisikan nama direktori untuk data latih dan data validasi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3f69bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# melakukan ekstraksi pada file zip\n",
    "import zipfile,os\n",
    "local_zip = 'archive.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp')\n",
    "zip_ref.close()\n",
    " \n",
    "base_dir = '/tmp/images'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'val')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ceaecf7",
   "metadata": {},
   "source": [
    "Setelah Anda jalankan kode di atas, perhatikanlah, direktori data latih dan data validasi masing-masing memiliki sub-direktori clean dan messy. Setiap sub-direktori menyimpan gambar yang sesuai dengan nama sub-direktori tersebut. Jadi, pada sub-direktori ‘clean’ terdapat gambar-gambar ruangan yang rapi dan pada sub-direktori ‘messy’ terdapat gambar-gambar ruangan yang berantakan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f85601e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clean', 'messy']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/tmp/images/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "821c2d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clean', 'messy']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/tmp/images/val')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ed15dc",
   "metadata": {},
   "source": [
    "Langkah selanjutnya, kita akan menerapkan ImageDataGenerator untuk data latih dan data validasi. ImageDataGenerator merupakan sebuah fungsi yang sangat berguna untuk mempersiapkan data latih dan data validasi. Beberapa kemudahan yang disediakan ImageDataGenerator antara lain, preprocessing data, pelabelan sampel otomatis, dan augmentasi gambar.\n",
    "\n",
    "Augmentasi gambar merupakan sebuah teknik yang dapat digunakan untuk memperbanyak data latih dengan cara menduplikasi gambar yang telah ada dengan menambahkan variasi tertentu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0baa4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    " \n",
    "train_datagen = ImageDataGenerator(\n",
    "                    rescale=1./255,\n",
    "                    rotation_range=20,\n",
    "                    horizontal_flip=True,\n",
    "                    shear_range = 0.2,\n",
    "                    fill_mode = 'nearest')\n",
    " \n",
    "test_datagen = ImageDataGenerator(\n",
    "                    rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498f1c54",
   "metadata": {},
   "source": [
    "Selanjutnya, siapkan data latih dan validasi dari kumpulan data gambar yang di-load dalam memori melalui fungsi flow() berikut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3081b2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 192 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,  # direktori data latih\n",
    "        target_size=(150, 150),  # mengubah resolusi seluruh gambar menjadi 150x150 piksel\n",
    "        batch_size=4,\n",
    "        # karena ini merupakan masalah klasifikasi 2 kelas, gunakan class_mode = 'binary'\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir, # direktori data validasi\n",
    "        target_size=(150, 150), # mengubah resolusi seluruh gambar menjadi 150x150 piksel\n",
    "        batch_size=4, # karena ini merupakan masalah klasifikasi 2 kelas gunakan class_mode = 'binary'\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdec9c88",
   "metadata": {},
   "source": [
    "Setelah data siap, kita bisa membangun model Convolutional Neural Network (CNN). Pembuatan model CNN pada keras mirip dengan pembuatan model Multi Layer Perceptron (MLP) yang dibahas pada modul sebelumnya. Perbedaannya terdapat pada empat lapis layer konvolusi dan max pooling. \n",
    "\n",
    " Fungsi dari layer konvolusi adalah untuk mengekstraksi atribut pada gambar. Sedangkan layer max pooling berguna untuk mereduksi resolusi gambar sehingga proses pelatihan model lebih cepat. Nah, pada model CNN, proses klasifikasi gambar hanya berfokus pada atribut-atribut unik yang membedakan tiap kategori. Sehingga, teknik ini dinilai lebih optimal dibandingkan hanya menggunakan model MLP yang membedakan tiap kategori dengan melihat keseluruhan piksel-piksel pada gambar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c9ab1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(512, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6517b722",
   "metadata": {},
   "source": [
    "Usai membuat model, kita bisa menggunakan fungsi summary() untuk melihat summary dari arsitektur model yang telah kita buat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55e9fca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 74, 74, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 72, 72, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 36, 36, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 34, 34, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPoolin  (None, 17, 17, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 15, 15, 512)       590336    \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPoolin  (None, 7, 7, 512)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               12845568  \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13529665 (51.61 MB)\n",
      "Trainable params: 13529665 (51.61 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4870caef",
   "metadata": {},
   "source": [
    "Bagaimana membaca model summary di atas?\n",
    "\n",
    "Berdasarkan hasil summary di atas, model yang kita buat terdiri dari empat lapis Convolutional dan MaxPoling layer, sebuah flatten layer, serta dua buah dense layer. Ingatlah bahwa dense layer terakhir merupakan output layer. Pada kasus klasifikasi biner, output model merupakan angka tunggal antara 0 dan 1. Sehingga, kita set dense layer terakhir = 1. Sementara itu, kolom “Param #” berisi informasi mengenai jumlah parameter pada tiap layer.\n",
    "\n",
    "Selanjutnya, kolom “Output Shape” berisi informasi ukuran output yang dihasilkan tiap layer. Jika diperhatikan, ukuran input gambar yang telah didefinisikan sebelumnya adalah sebesar (150, 150). Tapi pada convolutional layer pertama, setiap satu input gambar akan menghasilkan ukuran output (148, 148) sebanyak 32 gambar. Ukuran tersebut berkurang karena kita menggunakan filter dengan ukuran (3, 3) dengan jumlah filter sebanyak 32 filter. Sehingga, tiap satu input gambar akan menghasilkan 32 gambar baru dengan ukuran (148, 148). \n",
    "\n",
    "Kemudian, resolusi tiap gambar akan diperkecil dengan tetap mempertahankan informasi pada gambar menggunakan MaxPoling layer yang berukuran (2, 2). Hal ini  akan menghasilkan ukuran output gambar sebesar (74, 74). Nah, proses tersebut juga berlaku untuk Convolutional dan MaxPoling layer yang lain. \n",
    "\n",
    "Berikutnya, mari perhatikan flatten layer. Output dari MaxPoling layer terakhir yang terdiri dari 512 gambar dengan ukuran (7, 7) akan diubah ke dalam bentuk array 1D (tensor 1D). Hal ini  akan menghasilkan output berukuran (25088). \n",
    "\n",
    "Nah, output tersebut kemudian masuk ke dalam dense layer pertama yang memiliki 512 neuron. Sehingga, ia akan menghasilkan output dengan ukuran (512). Selanjutnya, output ini akan masuk pada dense layer kedua yang memiliki 1 neuron sehingga akan menghasilkan output dengan ukuran (1). Output dari layer terakhir inilah yang digunakan sebagai hasil akhir model untuk kasus klasifikasi biner."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd65c5c",
   "metadata": {},
   "source": [
    "Setelah membuat arsitektur model CNN, tahap selanjutnya adalah melakukan compile model tersebut menggunakan fungsi compile(). Pada tahap ini, kita juga menentukan loss function serta optimizer yang akan digunakan. Loss function yang digunakan pada kasus klasifikasi biner adalah \"binary_crossentropy\". Selain itu, optimizer yang digunakan  pada kasus ini adalah \"Adam optimizer\". Adam optimizer dipilih karena mudah diterapkan, lebih efisien secara komputasi dan kebutuhan memori yang lebih kecil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c3edb913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model dengan 'adam' optimizer loss function 'binary_crossentropy' \n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=tf.optimizers.Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d12dff6",
   "metadata": {},
   "source": [
    "Nah, tahap terakhir dari pembuatan model adalah proses yang disebut sebagai model fitting. Ia merupakan proses untuk melatih model pada data masukan dan label yang bersesuaian. Pada proses ini, kita memasukkan data latih pada jaringan Neural Network yang telah kita buat sebelumnya. \n",
    "\n",
    "Hal yang harus didefinisikan pada tahap ini adalah loss function dan optimizer. Kemudian, kita mulai proses pelatihan model dengan memanggil fungsi fit(). \n",
    "\n",
    "Dengan menggunakan ImageDataGenerator, kita tidak perlu memasukkan parameter gambar dan labelnya. Image data generator secara otomatis melabeli gambar sesuai dengan direktorinya. Sebagai contoh,  sebuah gambar yang terdapat di direktori clean, akan diberi label “clean” oleh ImageDataGenerator secara otomatis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "322e4658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:From c:\\Users\\YONANDA MAYLA\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\YONANDA MAYLA\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "25/25 - 4s - loss: 0.7978 - accuracy: 0.4500 - val_loss: 0.6930 - val_accuracy: 0.5000 - 4s/epoch - 161ms/step\n",
      "Epoch 2/20\n",
      "25/25 - 2s - loss: 0.6944 - accuracy: 0.5100 - val_loss: 0.6930 - val_accuracy: 0.5000 - 2s/epoch - 91ms/step\n",
      "Epoch 3/20\n",
      "25/25 - 2s - loss: 0.6961 - accuracy: 0.4800 - val_loss: 0.6761 - val_accuracy: 0.5500 - 2s/epoch - 86ms/step\n",
      "Epoch 4/20\n",
      "25/25 - 2s - loss: 0.6957 - accuracy: 0.5100 - val_loss: 0.6930 - val_accuracy: 0.5000 - 2s/epoch - 83ms/step\n",
      "Epoch 5/20\n",
      "25/25 - 2s - loss: 0.6934 - accuracy: 0.4900 - val_loss: 0.6919 - val_accuracy: 0.5000 - 2s/epoch - 84ms/step\n",
      "Epoch 6/20\n",
      "25/25 - 2s - loss: 0.7012 - accuracy: 0.5200 - val_loss: 0.6819 - val_accuracy: 0.5000 - 2s/epoch - 81ms/step\n",
      "Epoch 7/20\n",
      "25/25 - 2s - loss: 0.6820 - accuracy: 0.5500 - val_loss: 0.6971 - val_accuracy: 0.5000 - 2s/epoch - 85ms/step\n",
      "Epoch 8/20\n",
      "25/25 - 2s - loss: 0.7410 - accuracy: 0.5500 - val_loss: 0.6932 - val_accuracy: 0.5000 - 2s/epoch - 91ms/step\n",
      "Epoch 9/20\n",
      "25/25 - 2s - loss: 0.6924 - accuracy: 0.4600 - val_loss: 0.6874 - val_accuracy: 0.7500 - 2s/epoch - 89ms/step\n",
      "Epoch 10/20\n",
      "25/25 - 3s - loss: 0.6733 - accuracy: 0.5700 - val_loss: 0.6861 - val_accuracy: 0.8000 - 3s/epoch - 114ms/step\n",
      "Epoch 11/20\n",
      "25/25 - 6s - loss: 0.6924 - accuracy: 0.5200 - val_loss: 0.6920 - val_accuracy: 0.5000 - 6s/epoch - 239ms/step\n",
      "Epoch 12/20\n",
      "25/25 - 6s - loss: 0.6942 - accuracy: 0.4500 - val_loss: 0.6917 - val_accuracy: 0.5000 - 6s/epoch - 240ms/step\n",
      "Epoch 13/20\n",
      "25/25 - 6s - loss: 0.6867 - accuracy: 0.5100 - val_loss: 0.6487 - val_accuracy: 0.5000 - 6s/epoch - 249ms/step\n",
      "Epoch 14/20\n",
      "25/25 - 6s - loss: 0.7201 - accuracy: 0.6100 - val_loss: 0.6927 - val_accuracy: 0.5000 - 6s/epoch - 256ms/step\n",
      "Epoch 15/20\n",
      "25/25 - 7s - loss: 0.6940 - accuracy: 0.4900 - val_loss: 0.7026 - val_accuracy: 0.5000 - 7s/epoch - 261ms/step\n",
      "Epoch 16/20\n",
      "25/25 - 4s - loss: 0.6960 - accuracy: 0.5200 - val_loss: 0.6953 - val_accuracy: 0.5000 - 4s/epoch - 155ms/step\n",
      "Epoch 17/20\n",
      "25/25 - 2s - loss: 0.6959 - accuracy: 0.4900 - val_loss: 0.6934 - val_accuracy: 0.5000 - 2s/epoch - 86ms/step\n",
      "Epoch 18/20\n",
      "25/25 - 2s - loss: 0.6942 - accuracy: 0.4800 - val_loss: 0.6931 - val_accuracy: 0.5000 - 2s/epoch - 85ms/step\n",
      "Epoch 19/20\n",
      "25/25 - 2s - loss: 0.6927 - accuracy: 0.5200 - val_loss: 0.6930 - val_accuracy: 0.5000 - 2s/epoch - 86ms/step\n",
      "Epoch 20/20\n",
      "25/25 - 2s - loss: 0.6926 - accuracy: 0.5200 - val_loss: 0.6925 - val_accuracy: 0.5000 - 2s/epoch - 90ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2c936b130d0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# latih model dengan model.fit \n",
    "model.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=25,  # berapa batch yang akan dieksekusi pada setiap epoch\n",
    "      epochs=20, # tambahkan epochs jika akurasi model belum optimal\n",
    "      validation_data=validation_generator, # menampilkan akurasi pengujian data validasi\n",
    "      validation_steps=5,  # berapa batch yang akan dieksekusi pada setiap epoch\n",
    "      verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923118b2",
   "metadata": {},
   "source": [
    "Sampai di sini, proses training telah selesai. Kita telah berhasil membuat model machine learning dengan CNN untuk mengklasifikasi gambar ruangan yang bersih dan berantakan. \n",
    "\n",
    "Setelah berhasil membuat model, Kitatentu ingin menguji model tersebut untuk memprediksi gambar baru (gambar yang belum dikenal oleh model sebelumnya). Potongan program berikut memungkinkan kita secara interaktif memilih sebuah gambar. Kemudian, gambar tersebut akan diolah terlebih dahulu sebelum dimasukkan ke model untuk diprediksi. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
